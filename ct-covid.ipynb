{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54297d3b-c530-495b-abe2-8974bfbfa13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Trovati 20 file NIfTI.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CT volumes: 100%|████████████████████████████████████████████████████████| 20/20 [3:57:01<00:00, 711.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset creato:\n",
      "X (sinogrammi): (11420, 182, 180, 3)\n",
      "Y (slices): (11420, 128, 128)\n",
      "Dataset salvato in 'phase_contrast_dataset.npz'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize, radon\n",
    "import tomopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------\n",
    "# Parameters\n",
    "# -------------------------------\n",
    "N = 128                    # resize target per slice\n",
    "pixel_size = 1e-4          # pixel size in meters\n",
    "wavelength = 6.2e-11       # 20 keV X-rays ~ 0.062 nm\n",
    "k = 2 * np.pi / wavelength\n",
    "beta = 1e-10                # ridotto per evitare overflow\n",
    "delta = 5e-8                # ridotto per evitare overflow\n",
    "distances = [0.01, 0.001, 0.1]  # detector distances in meters\n",
    "num_angles = 180\n",
    "theta = np.linspace(0., 180., num_angles, endpoint=False)\n",
    "energy_keV = 20.0\n",
    "\n",
    "data_dir = \"./ct_scans\"\n",
    "nii_files = [f for f in os.listdir(data_dir) if f.endswith(\".nii\") or f.endswith(\".nii.gz\")]\n",
    "print(f\"Trovati {len(nii_files)} file NIfTI.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Phase contrast propagation\n",
    "# -------------------------------\n",
    "def propagate_phase_contrast(img, z, pixel_size, wavelength, delta, beta):\n",
    "    \"\"\"Simula phase contrast propagation di una slice 2D.\"\"\"\n",
    "    img = img.astype(np.float32)\n",
    "    trans = np.exp(-k * beta * img) * np.exp(-1j * k * delta * img)\n",
    "    \n",
    "    fx = np.fft.fftfreq(N, pixel_size)\n",
    "    fy = np.fft.fftfreq(N, pixel_size)\n",
    "    FX, FY = np.meshgrid(fx, fy, indexing='xy')\n",
    "    arg = 1.0 - (wavelength * FX)**2 - (wavelength * FY)**2\n",
    "    sqrt_term = np.sqrt(arg.astype(np.complex128))\n",
    "    H = np.exp(1j * 2 * np.pi * z / wavelength * sqrt_term)\n",
    "    \n",
    "    wave = np.fft.ifft2(np.fft.fft2(trans) * H)\n",
    "    I_phase = np.abs(wave)**2\n",
    "    return I_phase\n",
    "\n",
    "def phase_retrieve_image(I_phase, pixel_size, z, delta, beta, energy_keV):\n",
    "    \"\"\"Recupera fase usando TomoPy.\"\"\"\n",
    "    tomo = I_phase[np.newaxis, :, :].astype(np.float32)\n",
    "    pixel_size_cm = pixel_size * 100.0\n",
    "    dist_cm = z * 100.0\n",
    "    alpha = beta / delta\n",
    "    retrieved = tomopy.prep.phase.retrieve_phase(\n",
    "        tomo, pixel_size=pixel_size_cm, dist=dist_cm,\n",
    "        energy=energy_keV, alpha=alpha, pad=True\n",
    "    )\n",
    "    return retrieved[0, :, :]\n",
    "\n",
    "# -------------------------------\n",
    "# Dataset generation\n",
    "# -------------------------------\n",
    "X = []  # sinogrammi\n",
    "Y = []  # slice originali\n",
    "\n",
    "for nii_file in tqdm(nii_files, desc=\"Processing CT volumes\"):\n",
    "    path = os.path.join(data_dir, nii_file)\n",
    "    img_nii = nib.load(path)\n",
    "    vol = img_nii.get_fdata()\n",
    "    \n",
    "    # Assumiamo (H, W, num_slices), altrimenti trasponi\n",
    "    if vol.shape[2] < vol.shape[0] or vol.shape[2] < vol.shape[1]:\n",
    "        vol = np.transpose(vol, (1, 2, 0))\n",
    "    \n",
    "    # ciclo sulle slice\n",
    "    for i in range(vol.shape[2]):\n",
    "        slice_orig = vol[:, :, i]\n",
    "        \n",
    "        # ridimensiona a N×N\n",
    "        slice_resized = resize(slice_orig, (N, N), preserve_range=True)\n",
    "        \n",
    "        # Normalizzazione per evitare overflow\n",
    "        slice_clipped = np.clip(slice_resized, -1000, 3000)  # HU tipici\n",
    "        slice_norm = (slice_clipped - slice_clipped.min()) / (slice_clipped.max() - slice_clipped.min())\n",
    "        slice_norm = slice_norm.astype(np.float32)\n",
    "        \n",
    "        # stack phase contrast per più distanze\n",
    "        phase_stack = []\n",
    "        for z in distances:\n",
    "            I_phase = propagate_phase_contrast(slice_norm, z, pixel_size, wavelength, delta, beta)\n",
    "            retrieved = phase_retrieve_image(I_phase, pixel_size, z, delta, beta, energy_keV)\n",
    "            phase_stack.append(retrieved)\n",
    "        \n",
    "        multi_stack = np.stack(phase_stack, axis=-1)  # (N, N, num_distances)\n",
    "        \n",
    "        # calcola sinogrammi per ciascun canale\n",
    "        sinograms = [radon(multi_stack[:, :, j], theta=theta, circle=False) for j in range(len(distances))]\n",
    "        sinograms = np.stack(sinograms, axis=-1)  # (detector_pixels, num_angles, num_distances)\n",
    "        \n",
    "        X.append(sinograms)\n",
    "        Y.append(slice_norm)  # target normalizzato\n",
    "\n",
    "# converte in array NumPy\n",
    "X = np.array(X, dtype=np.float32)\n",
    "Y = np.array(Y, dtype=np.float32)\n",
    "\n",
    "print(\"Dataset creato:\")\n",
    "print(\"X (sinogrammi):\", X.shape)\n",
    "print(\"Y (slices):\", Y.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# Salvataggio su disco\n",
    "# -------------------------------\n",
    "np.savez_compressed(\"phase_contrast_dataset.npz\", X=X, Y=Y)\n",
    "print(\"Dataset salvato in 'phase_contrast_dataset.npz'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd210b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shapes: X=(11420, 182, 180, 3), Y=(11420, 128, 128)\n",
      "Y reshaped to: (11420, 128, 128, 1)\n",
      "Input shape: (182, 180, 3)\n",
      "Normalizing X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11420/11420 [00:04<00:00, 2438.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Train neural network on phase-contrast sinograms\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------\n",
    "# Parameters\n",
    "# -------------------------------\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "DATA_FILE = \"phase_contrast_dataset.npz\"   # dataset generato con il codice precedente\n",
    "MODEL_OUT = \"sino2img_cnn.h5\"\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "VAL_SPLIT = 0.15\n",
    "\n",
    "# -------------------------------\n",
    "# Load dataset\n",
    "# -------------------------------\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    raise FileNotFoundError(f\"{DATA_FILE} non trovato! Assicurati di aver eseguito il codice di generazione prima.\")\n",
    "\n",
    "data = np.load(DATA_FILE)\n",
    "X = data[\"X\"]\n",
    "Y = data[\"Y\"]\n",
    "\n",
    "print(f\"Loaded dataset shapes: X={X.shape}, Y={Y.shape}\")\n",
    "\n",
    "# Add channel dimension to Y if missing\n",
    "if Y.ndim == 3:\n",
    "    Y = Y[..., np.newaxis]\n",
    "print(\"Y reshaped to:\", Y.shape)\n",
    "\n",
    "input_shape = X.shape[1:]  # (detector_pixels, num_angles, num_distances)\n",
    "print(\"Input shape:\", input_shape)\n",
    "\n",
    "# -------------------------------\n",
    "# Normalize\n",
    "# -------------------------------\n",
    "def normalize_X(X):\n",
    "    Xn = np.empty_like(X, dtype=np.float32)\n",
    "    print(\"Normalizing X...\")\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        arr = X[i]\n",
    "        mn, mx = arr.min(), arr.max()\n",
    "        if mx > mn:\n",
    "            Xn[i] = (arr - mn) / (mx - mn)\n",
    "        else:\n",
    "            Xn[i] = arr\n",
    "    return Xn\n",
    "\n",
    "Xn = normalize_X(X)\n",
    "Y = np.clip(Y.astype(np.float32), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe200ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(DATA_FILE)\n",
    "X = data[\"X\"]\n",
    "Y = data[\"Y\"]\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=VAL_SPLIT, random_state=42)\n",
    "print(\"Train shapes:\", X_train.shape, Y_train.shape)\n",
    "print(\"Val shapes:\", X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dfbcde-c9ba-47c0-8f83-7e6c4e1e0e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shapes: X=(11420, 182, 180, 3), Y=(11420, 128, 128)\n",
      "Y reshaped to: (11420, 128, 128, 1)\n",
      "Input shape: (182, 180, 3)\n",
      "Normalizing X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11420/11420 [00:04<00:00, 2727.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Model definition\n",
    "# -------------------------------\n",
    "detector_pixels, num_angles, num_channels = input_shape\n",
    "output_H, output_W, _ = Y_train.shape[1:]\n",
    "\n",
    "def build_model(input_shape, base_filters=32):\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(base_filters, 3, padding=\"same\", activation=\"relu\")(inp)\n",
    "    x = layers.Conv2D(base_filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "    x = layers.Conv2D(base_filters*2, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(base_filters*2, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "    x = layers.Conv2D(base_filters*4, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(base_filters*4, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = layers.Conv2D(base_filters*2, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(base_filters*2, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = layers.Conv2D(base_filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(base_filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "    out = layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# -------------------------------\n",
    "# Compile\n",
    "# -------------------------------\n",
    "model.compile(optimizer=optimizers.Adam(1e-4), loss=\"mse\", metrics=[\"mae\"])\n",
    "cb_list = [\n",
    "    callbacks.ModelCheckpoint(MODEL_OUT, save_best_only=True, monitor=\"val_loss\"),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, verbose=1),\n",
    "    callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d08bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Train\n",
    "# -------------------------------\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=cb_list,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.save(MODEL_OUT)\n",
    "print(\"✅ Training finished. Model saved at\", MODEL_OUT)\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate and visualize\n",
    "# -------------------------------\n",
    "print(\"Evaluating model...\")\n",
    "val_preds = []\n",
    "for i in tqdm(range(0, len(X_val), BATCH_SIZE)):\n",
    "    preds = model.predict(X_val[i:i+BATCH_SIZE], verbose=0)\n",
    "    val_preds.append(preds)\n",
    "val_preds = np.concatenate(val_preds, axis=0)\n",
    "\n",
    "mse = np.mean((val_preds - Y_val)**2)\n",
    "mae = np.mean(np.abs(val_preds - Y_val))\n",
    "print(f\"Validation MSE={mse:.6f}, MAE={mae:.6f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Plot sample reconstructions\n",
    "# -------------------------------\n",
    "n_show = min(6, len(X_val))\n",
    "idxs = np.random.choice(len(X_val), n_show, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(n_show, 4, figsize=(12, 3*n_show))\n",
    "for r, i in enumerate(idxs):\n",
    "    sino = X_val[i, :, :, 0]\n",
    "    gt = Y_val[i, :, :, 0]\n",
    "    pred = val_preds[i, :, :, 0]\n",
    "    err = np.abs(gt - pred)\n",
    "\n",
    "    ax = axes[r, 0]\n",
    "    ax.imshow(sino.T, aspect=\"auto\")\n",
    "    ax.set_title(\"Sinogram (ch0)\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    ax = axes[r, 1]\n",
    "    ax.imshow(gt, cmap=\"gray\")\n",
    "    ax.set_title(\"Ground Truth\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    ax = axes[r, 2]\n",
    "    ax.imshow(pred, cmap=\"gray\")\n",
    "    ax.set_title(\"NN Reconstruction\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    ax = axes[r, 3]\n",
    "    im = ax.imshow(err, cmap=\"inferno\")\n",
    "    ax.set_title(\"Error\")\n",
    "    ax.axis(\"off\")\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# Plot training history\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Training Curve (log scale)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
